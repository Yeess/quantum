{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OBJECTIVES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. pull information going back to 2000\n",
    "2. breakdown port allocations in key reusable methods\n",
    "3. implement date rules to perform optimization at given intervals (date resample)\n",
    "4. calculate cumulative portfolio returns as portfolio allocation changes\n",
    "5. run sensitivities fine-tunning opt parameters (MVO day window, pos sizing, leverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from time import sleep\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cvx\n",
    "import re, os\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "component_path = \"./sector_components/\"\n",
    "pricing_path = \"./pricing/\"\n",
    "date_fmt = '%m-%d-%Y'\n",
    "log = True\n",
    "\n",
    "ticker_map = {\n",
    "    'benchmark': ['SPY'],\n",
    "    'equity': ['VTI','VTV','VOE','VBR','VEA','VWO'],\n",
    "    'fixed_income': ['VTIP', 'SHV', 'MUB', 'LQD', 'BNDX', 'EMB'],\n",
    "    'spy_sectors': ['XLE', 'XLU', 'XLK', 'XLB', 'XLP', 'XLY', 'XLI', 'XLV', 'XLF', 'XLRE']\n",
    "}\n",
    "\n",
    "sectors = ticker_map['spy_sectors']\n",
    "sector_tickers_map = {}\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8,
     13
    ]
   },
   "outputs": [],
   "source": [
    "compound = lambda x: (x + 1).cumprod()\n",
    "two_dec = lambda x: '%.4f' % x\n",
    "# need to fix this method\n",
    "def get_pricing(fname, ticker_list, start_date):\n",
    "    if log: print(\"Getting pricing for:\", fname, start_date)\n",
    "    px = web.DataReader(ticker_list,data_source='yahoo',start=start_date)['Adj Close']\n",
    "    px.to_csv(pricing_path + fname)\n",
    "    return px\n",
    "def load_pricing(f, idx_col):\n",
    "    fname = pricing_path + f\n",
    "    px = pd.read_csv(fname, index_col=idx_col, parse_dates=True)\n",
    "    if log: print(\"Loaded pricing for {}, with shape {}\".format(f, px.shape))\n",
    "    return px\n",
    "def show_weights(weights, labels, ret, sigma):\n",
    "    df = pd.DataFrame(weights, columns=labels)\n",
    "    df['return'] = ret * 252\n",
    "    df['sigma'] = sigma * np.sqrt(252)\n",
    "    df['sharpe'] = df['return'] / df['sigma']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "def get_mean_variance(rets):\n",
    "    w_len = rets.shape[1] # number of columns\n",
    "    eq_weights = np.asarray([1/w_len for _ in range(w_len)]) #default weights\n",
    "    mu = rets.mean()\n",
    "    std_dev = rets.std()\n",
    "    cov_matrix = rets.cov()\n",
    "    return w_len, eq_weights, mu.values, std_dev, cov_matrix.values    \n",
    "def get_mvo_allocations(n, mu_ret, cov_mtrx, min_sum=1, max_sum=1, min_w=0, max_w=0.2):\n",
    "    mu = mu_ret.T\n",
    "    Sigma = cov_mtrx\n",
    "    w = cvx.Variable(n)\n",
    "    gamma = cvx.Parameter(sign='positive')\n",
    "    ret = mu.T * w \n",
    "    risk = cvx.quad_form(w, Sigma)\n",
    "    # removed the min_sum\n",
    "    prob = cvx.Problem(cvx.Maximize(ret - gamma*risk), \n",
    "        [cvx.sum_entries(cvx.abs(w)) <= max_sum,\n",
    "         w > min_w,\n",
    "         w < max_w])\n",
    "    gamma.value = 50; prob.solve()\n",
    "    if prob.status == 'optimal': \n",
    "        return [i[0] for i in w.value.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     3,
     7,
     10,
     15
    ]
   },
   "outputs": [],
   "source": [
    "p_template = \"Ann. return: {0:.2f}%, std dev: {1:.2f}%, sharpe: {2:.2f}\"\n",
    "def calc_port_performance(arr, weights):\n",
    "    return np.cumprod(np.sum(arr * weights, axis=1) + 1)\n",
    "def date_rules(date_range, tgt_date_str, freq):\n",
    "    #return a list of dates\n",
    "    tgt_dt = datetime.strptime(tgt_date_str, date_fmt)\n",
    "    return date_range[:date_range.index(tgt_dt)+1][::-freq]\n",
    "def date_intervals(df, freq):\n",
    "    #using pandas\n",
    "    return df.resample(freq, closed='left', label='left').mean()\n",
    "def portfolio_metrics(pdf):\n",
    "    ret = (pdf.pct_change().mean() * 252).values[0]\n",
    "    std = (pdf.pct_change().std() * sqrt(252)).values[0]\n",
    "    if log: print(p_template.format(ret * 100, std * 100, ret / std))\n",
    "    return ret, std, ret / std\n",
    "def recomend_allocs(w, irange, top):\n",
    "    w = (w.loc[irange].sum(axis=0).sort_values(ascending=False) / max_w_const).astype(np.int)\n",
    "    return w[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_weights(px, freq, lb=20, min_sum=1, max_sum=1, min_w=0, max_w=0.1):\n",
    "    px.dropna(axis=1, inplace=True)\n",
    "    returns = px.sort_index().pct_change(); returns.iloc[0] = 0\n",
    "    intervals = pd.to_datetime(date_intervals(returns, freq).index.tolist())\n",
    "    valid_dates = [d for d in intervals if d in returns.index]    \n",
    "    #cols = returns.columns    \n",
    "    hist_alloc = pd.DataFrame(np.zeros((returns.shape)), index=returns.index, columns=returns.columns)\n",
    "    #if log: \n",
    "        #print(\"Empty allocations:\", hist_alloc.shape)\n",
    "        #print('{0:d} stocks, {1:d} days, {2:d} lookback'.format(len(returns.columns), len(px), lb))\n",
    "\n",
    "    for i in valid_dates:\n",
    "        lb_returns = returns.loc[:i.date()].tail(lb).dropna()\n",
    "        weights = np.array([0 for _ in range(len(returns.columns))])\n",
    "        if (len(lb_returns) > 2):\n",
    "            n, weights, mu_ret, std_dev, cov_mtrx = get_mean_variance(lb_returns)\n",
    "            weights = get_mvo_allocations(\n",
    "                n, mu_ret, cov_mtrx, min_sum=min_sum, max_sum=max_sum, min_w=min_w, max_w=max_w)\n",
    "        hist_alloc.loc[i.date()] = weights\n",
    "\n",
    "    hist_alloc = hist_alloc.loc[returns.index].replace(0, np.nan).fillna(method='ffill')\n",
    "    hist_alloc.replace(np.nan, 0, inplace=True)\n",
    "    \n",
    "    #if log: print(\"returns: days / stocks\", returns.shape, \"allocation: days / stocks\", hist_alloc.shape)\n",
    "    return returns, hist_alloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Test Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "numdays, cols = 252, 10\n",
    "\n",
    "np.random.seed(42)\n",
    "numdays, cols = 100, 10\n",
    "end_date_str, tgt_date_str = '12-31-2017', '12-27-2017'\n",
    "freq = 7; lookback = 20\n",
    "\n",
    "arr = (np.random.rand(numdays, cols) - 0.5) / 10\n",
    "weights = np.random.rand(1, cols)\n",
    "weights = weights / np.sum(weights, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test the portfolio performance calculation\n",
    "port_perf = calc_port_performance(arr, weights)\n",
    "#pd.DataFrame(port_perf).plot()\n",
    "port_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test the date rules / intervals\n",
    "end_date = datetime.strptime(end_date_str, date_fmt)\n",
    "d_rng = sorted([end_date - timedelta(x) for x in range(0, numdays)]) # using list comprenhensions\n",
    "sorted(date_rules(d_rng, tgt_date_str, freq))\n",
    "\n",
    "d_rng = pd.date_range(end=end_date_str, freq='D', periods=numdays) # using pandas date range\n",
    "d_rng = list(pd.to_datetime(d_rng))\n",
    "intervals = list(sorted(date_rules(d_rng, tgt_date_str, freq)))\n",
    "print(\"check:\", len(intervals), \"equals\", numdays // freq, \"result:\",len(intervals) == numdays // freq) # check if intervals works\n",
    "intervals[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_rng = pd.date_range(end=end_date_str, freq='D', periods=numdays) # using pandas date range\n",
    "d_rng = list(pd.to_datetime(d_rng))\n",
    "\n",
    "df = pd.DataFrame(arr, index=d_rng, columns=[i for i in range(cols)])\n",
    "(df+1).cumprod().mean(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test both the portfolio performance using date intervals without optimization / equal weights\n",
    "date_range = list(df.index)\n",
    "intervals = list(sorted(date_rules(date_range, tgt_date_str, freq)))\n",
    "hist_alloc = pd.DataFrame(np.zeros((len(df),cols)), index=df.index)\n",
    "\n",
    "for i in intervals:\n",
    "    #lb_returns = df.loc[:i.date()].tail(lookback)\n",
    "    weights = np.array([1/cols for _ in range(cols)])\n",
    "    #print(['{0:.2f}'.format(x) for x in weights])\n",
    "    hist_alloc.loc[i.date()] = weights\n",
    "\n",
    "hist_alloc.loc[intervals[0]:] = hist_alloc.loc[intervals[0]:].replace(0, np.nan).fillna(method='ffill')\n",
    "\n",
    "port_perf = calc_port_performance(df.values, hist_alloc.values)\n",
    "pd.DataFrame(port_perf).plot()\n",
    "port_perf[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test both the portfolio performance using date intervals with optimization\n",
    "date_range = list(df.index)\n",
    "intervals = list(sorted(date_rules(date_range, tgt_date_str, freq)))\n",
    "hist_alloc = pd.DataFrame(np.zeros((len(df),cols)), index=df.index)\n",
    "\n",
    "for i in intervals:\n",
    "    lb_returns = df.loc[:i.date()].tail(lookback)\n",
    "    n, weights, mean_returns, std_dev, cov_matrix = get_mean_variance(lb_returns)\n",
    "    weights = get_mvo_allocations(n, mean_returns, cov_matrix, min_w=0.0, max_w=0.3)\n",
    "    #print(['{0:.2f}'.format(x) for x in weights])\n",
    "    hist_alloc.loc[i.date()] = weights\n",
    "\n",
    "hist_alloc.loc[intervals[0]:] = hist_alloc.loc[intervals[0]:].replace(0, np.nan).fillna(method='ffill')\n",
    "hist_alloc\n",
    "\n",
    "port_perf = calc_port_performance(df.values, hist_alloc.values)\n",
    "pdf = pd.DataFrame(port_perf)\n",
    "pdf.plot()\n",
    "port_perf[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from hard-drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     12
    ]
   },
   "outputs": [],
   "source": [
    "# load sector components\n",
    "flist = os.listdir(component_path)\n",
    "colstoload = ['Symbol','Company Name', 'Index Weight']\n",
    "pattern = r'holdings-'\n",
    "files = [f for f in flist if f.startswith(pattern)]\n",
    "companies = pd.DataFrame([])\n",
    "for s in sectors:\n",
    "    fname = component_path + pattern + s.lower() + '.csv'\n",
    "    df = pd.read_csv(fname, skiprows=1, index_col='Symbol', usecols=colstoload)\n",
    "    df['ETF'] = s\n",
    "    sector_tickers_map[s] = df.index.tolist()\n",
    "    companies = companies.append(df)\n",
    "if log: \n",
    "    print(\"Company Sample:\", companies.shape); \n",
    "    print(companies.groupby('ETF')['Index Weight'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads from hard drive pricing for components and corresponding sector\n",
    "dwld_key = 'XLK'\n",
    "px = load_pricing(dwld_key + '-hold-pricing.csv', 'Date')\n",
    "#spyder_etfs = load_pricing('spyders.csv', 'Date')\n",
    "spyder_etf = load_pricing(dwld_key + '.csv', 'Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data from the Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_window = 252*10\n",
    "end_date_str = tgt_date_str = '1-8-2018'\n",
    "start_date = datetime.strptime('1-8-2018', date_fmt)\n",
    "start_date = start_date - timedelta(hist_window)\n",
    "start_date = start_date.strftime(date_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Downloads pricing on all components for each ETF\n",
    "etfs = [e for e in sectors]\n",
    "sleep_time = 5\n",
    "\n",
    "def download_sector(etf, start_date):\n",
    "    tickers = sector_tickers_map[etf] # for individual components\n",
    "    get_pricing(etf + '-hold-pricing.csv', tickers, start_date)\n",
    "\n",
    "#downloads all components of each sector\n",
    "while len(etfs) > 0: \n",
    "    try:\n",
    "        val = etfs[-1]; download_sector(val, start_date); etfs.pop()\n",
    "    except Exception as err:\n",
    "        print(\"Error: {0}, waiting to try again in {1}\".format(err, sleep_time))\n",
    "        sleep(sleep_time)\n",
    "#downloads all sector ETFs\n",
    "while True:\n",
    "    try:\n",
    "        sectors; get_pricing('sectors.csv', sectors, start_date); break\n",
    "    except Exception as err:\n",
    "        print(\"Error: {0}, waiting to try again in {1}\".format(err, sleep_time))\n",
    "        sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting pricing for: sectors.csv 02-14-2011\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Downloads pricing from yahoo for components + sector ETF\n",
    "tickers = sector_tickers_map[dwld_key] # for individual components\n",
    "#tickers = ticker_map[\"sectors\"] # for individual ETFs\n",
    "px = get_pricing(dwld_key + '-hold-pricing.csv', tickers, start_date.strftime(date_fmt))\n",
    "etf = get_pricing(dwld_key + '.csv', dwld_key, start_date.strftime(date_fmt))\n",
    "spyder_etf = pd.DataFrame(etf)\n",
    "spyder_etf.index.name = \"Date\"\n",
    "spyder_etf.columns=[dwld_key]\n",
    "spyder_etf.to_csv(dwld_key + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Run Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "TODO List\n",
    "1. Produce ETF level recomendation (sector weightings)\n",
    "2. Produce recomendations for each sector\n",
    "3. Show spread returns starting at different times for each sector\n",
    "4. Calculate sharpe rankings for a given company list\n",
    "5. Create long / short optimizers\n",
    "6. Test portofolio with both long and shorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run a one time fixed time-lenght optimization\n",
    "frame = (-252*10); freq = \"W-WED\"; lookback = 20; \n",
    "min_gross=1; max_gross=1; min_w=0; max_w=0.2\n",
    "frequency = \"W-WED\"\n",
    "px.dropna(axis=0, inplace=True)\n",
    "px.dropna(axis=1, inplace=True)\n",
    "px_portion = px[frame:].copy()\n",
    "s_etf = (spyder_etf[-len(px_portion):].pct_change() + 1).cumprod()\n",
    "returns, alloc = get_weights(\n",
    "    px_portion, frequency, lb=lookback, max_sum=max_gross, min_w=min_w, max_w=max_w)\n",
    "port_perf = calc_port_performance(returns.values, alloc.values)\n",
    "pdf = pd.DataFrame(port_perf, index=returns.index, columns=[dwld_key + \"-cvxopt\"])\n",
    "portfolio_metrics(pdf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot optimization\n",
    "ax = pdf.plot(); s_etf.plot(ax=ax, legend='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create Chart to show return spread vs. ETF for a given time window\n",
    "msg = \"Portfolio metrics starting every {} trading days and holding for {} days\"\n",
    "holding = 180; stop = int(len(alloc) - holding); jumps = 20\n",
    "offsets = [x for x in range(0, stop, jumps)]\n",
    "print(msg.format(jumps, holding))\n",
    "cols = [\"CumProd_M2\", \"CumProd_Bechmark\", \"M2_Return\", \"M2_StdDev\", \"M2_Sharpe\"]\n",
    "results = pd.DataFrame([], index=offsets, columns=cols)\n",
    "for o in offsets:\n",
    "    start = np.min([o, len(alloc)-1])\n",
    "    end = np.min([o+holding, len(alloc)])\n",
    "    p = px_portion[start:end].copy()\n",
    "    s_etf = (spyder_etf[-len(px_portion):][start:end].pct_change() + 1).prod()\n",
    "    r, w = get_weights(p, \"W-WED\", max_w=0.10)\n",
    "    port_perf = calc_port_performance(r.values, w.values)\n",
    "    pdf = pd.DataFrame(port_perf, index=r.index) # index by date\n",
    "    ret, std, sharpe = portfolio_metrics(pdf)\n",
    "    results.loc[o, cols]= [pdf[-1:].values[0][0], s_etf.values[0], ret, std, sharpe]\n",
    "results[[\"CumProd_M2\", \"CumProd_Bechmark\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results[results[\"CumProd_M2\"] < results[\"CumProd_Bechmark\"]].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show portfolio metrics for a given time window\n",
    "length = 252\n",
    "w = alloc[-length:].astype(np.float)\n",
    "r = returns[-length:].astype(np.float)\n",
    "port_perf = calc_port_performance(r.values, w.values)\n",
    "pdf = pd.DataFrame(port_perf, index=r.index, columns=[dwld_key + \"-cvxopt\"])\n",
    "portfolio_metrics(pdf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show portfolio performance by year\n",
    "perf_by_years(returns, alloc, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot portfolio performance by year\n",
    "first_year = int(alloc.index[0].year)\n",
    "last_year = int(alloc.index[-1].year)\n",
    "years = [y for y in range(first_year, last_year, 1)] \n",
    "\n",
    "def perf_by_years(r, a, years):\n",
    "    ax = plt.axes()\n",
    "    for y in years:\n",
    "        year = str(y)\n",
    "        w = alloc.loc[year].astype(np.float16)\n",
    "        r = returns.loc[year].astype(np.float16)\n",
    "        p_perf = calc_port_performance(r.values, w.values)\n",
    "        result = pd.DataFrame(p_perf, index=w.index, columns=[year])\n",
    "        result.plot(title='Optimal Components of ' + dwld_key, ax=ax, legend='right')\n",
    "        if log: print(year, result[-1:].values[0][0])\n",
    "\n",
    "perf_by_years(returns, alloc, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show top holdings and last recomended holding set\n",
    "w = alloc[-length:].astype(np.float16)\n",
    "intervals = pd.to_datetime(date_intervals(r, freq).index.tolist())\n",
    "\n",
    "top = 10\n",
    "irange = intervals\n",
    "print(\"Top {} holdings during the last {} intervals\".format(top, len(irange)))\n",
    "print(recomend_allocs(w, irange, top))\n",
    "\n",
    "irange = intervals[-5:]\n",
    "print(\"Top {} holdings during the last {} intervals\".format(top, len(irange)))\n",
    "print(recomend_allocs(w, irange, top))\n",
    "\n",
    "irange = intervals[-1:]\n",
    "print(\"Top {} holdings during the last {} intervals\".format(top, len(irange)))\n",
    "print(recomend_allocs(w, irange, top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lbs = [x for x in range(5, 15, 5)]\n",
    "mws = (np.array([x for x in range(4, 24, 4)]) / 100).tolist()\n",
    "for i, l in enumerate(lbs):\n",
    "    for j, w in enumerate(mws):\n",
    "        print(l, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "code_folding": [
     0,
     21
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_matrix(px, start, end, step):\n",
    "    print(\"Creating Sensitivity Matrix...\")\n",
    "    lbs = [x for x in range(start, end, step)]\n",
    "    mws = (np.array([x for x in range(start, end, step)]) / 100).tolist()\n",
    "    df = pd.DataFrame([], index=mws, columns=lbs)\n",
    "    df.index.name = \"Max Exposure\"\n",
    "    df.columns.name = \"Lookback\"\n",
    "    \n",
    "    for i, l in enumerate(lbs):\n",
    "        for j, w in enumerate(mws):\n",
    "            r, w = get_weights(px_portion, freq, lb=l, max_w=w)\n",
    "            port_perf = calc_port_performance(r.values, w.values)\n",
    "            pdf = pd.DataFrame(port_perf, index=r.index, columns=[dwld_key + \"-cvxopt\"])\n",
    "            days = len(pdf)\n",
    "            ret, std, sharpe = portfolio_metrics(pdf);\n",
    "            df.iloc[i, j] = (\n",
    "                ret.astype(np.float16), \n",
    "                std.astype(np.float16), \n",
    "                sharpe.astype(np.float16))\n",
    "    print(\"Complete\")\n",
    "    return df\n",
    "def heatmap(df, cmap = plt.cm.inferno): \n",
    "    fig = plt.figure() \n",
    "    ax = fig.add_subplot(111) \n",
    "    axim = ax.imshow(df.values, cmap=cmap, interpolation='nearest')\n",
    "    ax.set_xlabel(df.columns.name) \n",
    "    ax.set_xticks(np.arange(len(df.columns)))\n",
    "    ax.set_xticklabels(list(df.columns))\n",
    "    ax.set_ylabel(df.index.name)\n",
    "    ax.set_yticks(np.arange(len(df.index)))\n",
    "    ax.set_yticklabels( list(df.index))\n",
    "    plt.colorbar(axim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sm = create_matrix(px, 10, 20, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "curr = 2\n",
    "m_list = [\"Return\", \"StdDev\", \"Sharpe\"]\n",
    "print(\"Showing:\", m_list[curr])\n",
    "extract = lambda x: x[curr]\n",
    "df = sm.applymap(extract)\n",
    "heatmap(df.astype(float), cmap = plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Old Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#CHECK compounding math\n",
    "#what were the top 10 allocations tickers?\n",
    "top_stocks = alloc.sum(axis=0).sort_values(ascending=False)[:10].index.tolist()\n",
    "# what was their allocation?\n",
    "alloc = alloc[top_stocks]\n",
    "# how much did we allocate to them?\n",
    "cum_alloc = alloc.sum(axis=1)\n",
    "# multiply the daily returns of top allocations times our allocation\n",
    "port_return = (returns[top_stocks] * alloc).sum(axis=1)\n",
    "# we add 1 to get the compounding index\n",
    "port_index = (port_return + 1).cumprod()\n",
    "#cumulative return for the portfolio\n",
    "print(port_index[-1:], len(port_index), \"days\")\n",
    "\n",
    "port_perf = calc_port_performance(returns[top_stocks].values, alloc.values)\n",
    "print(port_perf[-1:], len(port_perf), \"days\")\n",
    "print(\"annual return\", pd.Series(port_perf).pct_change().mean() * 252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# show behaviour during sepcific time window\n",
    "start = '1-1-2017'; days = 15\n",
    "end = datetime.strptime(start, date_fmt) + timedelta(days)\n",
    "window = pdf.loc['2017-1-31':'2017-9-30']\n",
    "portfolio_metrics(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for s in sector_tickers_map.keys():\n",
    "    print(len(sector_tickers_map[s]))\n",
    "    \n",
    "#test both the portfolio performance using date intervals with optimization\n",
    "df = pd.DataFrame(arr, index=d_rng, columns=[i for i in range(cols)])\n",
    "date_range = list(df.index)\n",
    "intervals = list(sorted(date_rules(date_range, tgt_date_str, freq)))\n",
    "hist_allocations = pd.DataFrame(np.zeros((len(intervals),cols)), index=pd.to_datetime(intervals))\n",
    "\n",
    "for i in intervals:\n",
    "    lb_returns = df.loc[:i.date()].tail(lookback)\n",
    "    w_len, weights, mean_returns, std_dev, cov_matrix = get_mean_variance(lb_returns)\n",
    "    weights = get_mvo_allocations(mean_returns, cov_matrix)\n",
    "    hist_allocations.loc[i.date()] = weights\n",
    "\n",
    "port_perf = calc_port_performance(df.loc[intervals].values, hist_allocations.values)\n",
    "pd.DataFrame(port_perf).plot()\n",
    "port_perf[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "px = get_pricing(ticker_map[key], '01/01/2017')\n",
    "returns = px.sort_index().pct_change()\n",
    "compound(returns).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w_len, weights, mean_returns, std_dev, cov_matrix = get_mean_variance(returns)\n",
    "\n",
    "ann_returns = np.dot((mean_returns * 252), weights)\n",
    "ann_stdev = np.sqrt(252/len(returns)) * std_dev\n",
    "print(weights.shape, cov_matrix.shape)\n",
    "port_variance = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(252)\n",
    "print(\"eq weight return(exp)\", ann_returns)\n",
    "print(\"port risk(exp):\", port_variance)\n",
    "print(\"sharpe ratio:\", ann_returns / port_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Long only portfolio optimization.\n",
    "weights = get_mvo_allocations(mean_returns, cov_matrix)\n",
    "np_weights = np.array([weights]).T\n",
    "exp_return = np.dot(np.array([mean_daily_returns.values]), np_weights) * 252\n",
    "portfolio_std_dev = np.sqrt(np.dot(np_weights.T, np.dot(cov_matrix, np_weights))) * np.sqrt(252)\n",
    "print(\"optimized return(exp):\", exp_return)\n",
    "print(\"optimized portfolio risk(exp):\", portfolio_std_dev)\n",
    "print(\"sharpe ratio:\", exp_return / portfolio_std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compute trade-off curve.\n",
    "SAMPLES = 100\n",
    "weights = []\n",
    "risk_data = np.zeros(SAMPLES)\n",
    "ret_data = np.zeros(SAMPLES)\n",
    "gamma_vals = np.logspace(-2, 3, num=SAMPLES)\n",
    "for i in range(SAMPLES):\n",
    "    gamma.value = gamma_vals[i]\n",
    "    prob.solve()\n",
    "    weights.append([i[0] for i in w.value.tolist()])\n",
    "    risk_data[i] = cvx.sqrt(risk).value\n",
    "    ret_data[i] = ret.value\n",
    "print('Optimization status:', prob.status)\n",
    "#w.value, risk_data, ret_data\n",
    "#ret_data / risk_data # sharpe ratio\n",
    "#risk_data[np.argmin(risk_data)], risk_data[np.argmax(ret_data)]\n",
    "#wgt_cum_ret = (ret_data + 1).cumprod()\n",
    "cols = returns.columns.tolist();\n",
    "allocs = show_weights(weights, returns.columns, ret_data, risk_data); allocs.tail()\n",
    "allocs[cols].plot()\n",
    "print(allocs[-1:].apply(two_dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot long only trade-off curve.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "markers_on = range(1, 100, 10)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(risk_data, ret_data, 'g-')\n",
    "for marker in markers_on:\n",
    "    plt.plot(risk_data[marker], ret_data[marker], 'bs')\n",
    "    #ax.annotate(r\"$\\gamma = %.2f$\" % gamma_vals[marker], xy=(risk_data[marker], ret_data[marker]))\n",
    "for i in range(n):\n",
    "    plt.plot(sqrt(Sigma[i,i]).value, mu[i], 'ro')\n",
    "    ax.annotate(returns.columns[i], xy=(sqrt(Sigma[i,i]).value, mu[i]))\n",
    "plt.xlabel('Standard deviation')\n",
    "plt.ylabel('Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gamma_vals.shape, risk_data.shape, ret_data.shape\n",
    "summary = pd.DataFrame([], columns=['gamma', 'risk', 'return'], index=range(SAMPLES))\n",
    "summary['gamma'] = np.array([gamma_vals]).T\n",
    "summary['risk'] = np.array([risk_data]).T\n",
    "summary['return'] = np.array([ret_data]).T\n",
    "summary[['risk','return']].plot(kind='line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
