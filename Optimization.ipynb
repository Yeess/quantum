{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "\n",
    "frame = 20 #for limiting the range of optimizations, 1 year\n",
    "frequency = \"W-THU\"; lb = 20 # initial value for lookback\n",
    "min_gross=0.5; max_gross=1; min_w=0; max_w=0.1 # default optimization vars\n",
    "active_etf = None # ETF name OR None for broad market\n",
    "consol_px=pd.read_pickle(\"consol_px.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_allocation(alloc, min_weight):\n",
    "    last_alloc = alloc[-1:].T\n",
    "    last_alloc.columns = ['Allocation']\n",
    "    last_alloc = last_alloc[last_alloc[last_alloc.columns[0]] > min_weight]\n",
    "    return last_alloc\n",
    "\n",
    "\n",
    "def port_metrics(px, rec):\n",
    "    # this is supposed to be the righ way to calculate the portfolio risk\n",
    "    px.sort_index(inplace=True)\n",
    "    returns = px[rec.index.tolist()].pct_change()\n",
    "    mean_daily_returns = returns.mean()\n",
    "    cov_matrix = returns.cov()\n",
    "    weights = np.asarray(rec.values)\n",
    "    mult = len(mean_daily_returns)\n",
    "    #port_return = np.sum(mean_daily_returns.values * weights) * mult # bug fix\n",
    "    port_return = np.dot(mean_daily_returns.values, weights) * mult\n",
    "    port_risk = np.sqrt(np.dot(weights.T, np.dot(gb_matrix.values, weights))) * np.sqrt(mult)\n",
    "    return port_return[0], port_risk[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "cleanmin = lambda x: max(float(x), 1)\n",
    "def clean_nas(df):\n",
    "    cols = df.count().sort_values()[df.count().sort_values() < 1].index.tolist()\n",
    "    df = df.drop(cols, axis=1)\n",
    "    df.fillna(method='pad', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    df = df.applymap(cleanmin)\n",
    "    return df\n",
    "\n",
    "cols = consol_px.count().sort_values()[consol_px.count().sort_values() < 1].index.tolist()\n",
    "\n",
    "clean_nas(consol_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def date_intervals(df, freq):\n",
    "    #using pandas\n",
    "    return df.resample(freq, closed='left', label='left').mean()\n",
    "\n",
    "# Mean variance optimization\n",
    "def get_mean_variance(rets):\n",
    "    w_len = rets.shape[1] # number of columns\n",
    "    eq_weights = np.asarray([1/w_len for _ in range(w_len)]) #default weights\n",
    "    mu = rets.mean()\n",
    "    std_dev = rets.std()\n",
    "    cov_matrix = rets.cov()\n",
    "    return w_len, eq_weights, mu.values, std_dev, cov_matrix.values  \n",
    "\n",
    "\n",
    "def get_mvo_allocations(n, mu_ret, cov_mtrx, min_sum, max_sum, min_w, max_w, gamma_val):\n",
    "    mu = mu_ret.T\n",
    "    Sigma = cov_mtrx\n",
    "    w = cvx.Variable(n)\n",
    "    gamma = cvx.Parameter(sign='positive')\n",
    "    ret = mu.T * w \n",
    "    risk = cvx.quad_form(w, Sigma)\n",
    "    prob = cvx.Problem(cvx.Maximize(ret - gamma*risk), \n",
    "        [cvx.sum_entries(w) >= min_sum, cvx.sum_entries(w) <= max_sum, \n",
    "         w > min_w, w < max_w])\n",
    "    gamma.value = gamma_val\n",
    "    prob.solve()\n",
    "    if prob.status == 'optimal': \n",
    "        return [i[0] for i in w.value.tolist()]\n",
    "\n",
    "def get_weights(px, freq, lb, min_sum, max_sum, min_w, max_w, gamma):\n",
    "    px = clean_nas(px)\n",
    "    returns = px.sort_index().pct_change(); returns.iloc[0] = 0\n",
    "    intervals = pd.to_datetime(date_intervals(returns, freq).index.tolist())\n",
    "    valid_dates = [d for d in intervals if d in returns.index]    \n",
    "    hist_alloc = pd.DataFrame(np.zeros((returns.shape)), index=returns.index, columns=returns.columns)\n",
    "    for i in valid_dates:\n",
    "        lb_returns = returns.loc[:i.date()].tail(lb).dropna()\n",
    "        weights = np.array([0 for _ in range(len(returns.columns))])\n",
    "        if (len(lb_returns) > 2):\n",
    "            n, weights, mu_ret, std_dev, cov_mtrx = get_mean_variance(lb_returns)\n",
    "            weights = get_mvo_allocations(\n",
    "                n, mu_ret, cov_mtrx, min_sum, max_sum, min_w, max_w, gamma)\n",
    "        hist_alloc.loc[i.date()] = weights\n",
    "    hist_alloc = hist_alloc.loc[returns.index].replace(0, np.nan).fillna(method='ffill')\n",
    "    hist_alloc.replace(np.nan, 0, inplace=True)\n",
    "    return returns, hist_alloc\n",
    "\n",
    "\n",
    "def calc_port_performance(arr, weights):\n",
    "    return np.cumprod(np.sum(arr * weights, axis=1) + 1)\n",
    "\n",
    "\n",
    "def recommend_allocs(px, frame, lb, freq, min_sum, max_sum, min_w, max_w, gamma):\n",
    "    px = clean_nas(px)\n",
    "    px_portion = px[-abs(frame):].copy() \n",
    "    returns, alloc = get_weights(\n",
    "        px_portion, freq, lb, min_sum, max_sum, min_w, max_w, gamma)\n",
    "    port_perf = calc_port_performance(returns.values, alloc.values)\n",
    "    pdf = pd.DataFrame(port_perf, index=returns.index, columns=[\"M2-cvxopt\"])\n",
    "    return px_portion, returns, alloc, pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Finds the best gamma risk parameter\n",
    "SAMPLES = 100\n",
    "gamma_vals = np.logspace(-2, 3, num=SAMPLES)\n",
    "opt_cols = [\"Return\", \"Risk\", \"Sharpe\"]\n",
    "opt_df = pd.DataFrame([], index=gamma_vals, columns=opt_cols)\n",
    "\n",
    "for i in gamma_vals:\n",
    "    px_portion, _, alloc, pdf = recommend_allocs(\n",
    "        consol_px, frame, lb, frequency, min_gross, max_gross, min_w, max_w, i)\n",
    "    rec = last_allocation(alloc, 0.01)\n",
    "    ret, risk = port_metrics(px_portion, rec)\n",
    "    opt_df.loc[i][opt_cols] = [ret, risk, ret / risk]\n",
    "\n",
    "top = 5; best_gamma_ports = opt_df.sort_values(by='Sharpe', ascending=False).head(top)\n",
    "top_gammas = best_gamma_ports.index.tolist(); gamma_val = top_gammas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def portfolio_metrics(name, pdf):\n",
    "    timespan = len(pdf)\n",
    "    ret = (pdf.pct_change().mean() * timespan).values[0]\n",
    "    std = (pdf.pct_change().std() * sqrt(timespan)).values[0]\n",
    "    if log: print(p_template.format(name, ret, std, ret / std))\n",
    "    return ret, std, ret / std\n",
    "\n",
    "portfolio_metrics('Benchmark', px_spy.loc[pdf.index]);\n",
    "best_gamma_ports.head(top)\n",
    "# Creates matrix of lookbacks and weights to determine the best combination\n",
    "lbs = [x for x in range(5, 25, 5)]\n",
    "ws = [y/100 for y in [x for x in range(5, 20, 5)]]\n",
    "\n",
    "mtx_cols = [\"Lookback\", \"Weight\"]\n",
    "mtx_cols.extend(opt_cols)\n",
    "mtx_df = pd.DataFrame([], index=range(len(lbs) * len(ws)), columns=mtx_cols)\n",
    "\n",
    "log = True; i = 0\n",
    "for l in lbs:\n",
    "    for w in ws:\n",
    "        px_portion, _, alloc, _ = recommend_allocs(\n",
    "            consol_px, frame, l, frequency, min_gross, max_gross, min_w, w, gamma_val)\n",
    "        rec = last_allocation(alloc, 0.01); tickers = rec.index.tolist()\n",
    "        ret, risk = port_metrics(px_portion, rec)\n",
    "        mtx_df.loc[i][mtx_cols] = [l, w, ret, risk, ret / risk]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "mtx_df = mtx_df.sort_values(by='Return', ascending=False)\n",
    "lb, max_w = mtx_df.iloc[0]['Lookback'], mtx_df.iloc[0]['Weight']\n",
    "print(\"Gamma: {0:.2f}, Lookback: {1}, Max Weight: {2}\".format(gamma_val, lb, max_w))\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "# what is the difference between port with gammas 1..5?\n",
    "def rr_portfolios(g_list):\n",
    "    best_ports = pd.DataFrame([], index=g_list)\n",
    "    for g in g_list:\n",
    "        _, _, alloc, _ = recommend_allocs(consol_px, frame, lb, frequency, min_gross, max_gross, min_w, max_w, g)\n",
    "        rec = last_allocation(alloc, 0.01);\n",
    "        df1 = pd.DataFrame(rec.T.values, index=[g], columns=rec.index.tolist())\n",
    "        best_ports = best_ports.combine_first(df1)\n",
    "    return best_ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "universe = 'spy-sectors' \n",
    "component_path = \"/Users/Yes/Quantum/quantum/sector_components/\"\n",
    "sector_tickers_map = {}\n",
    "ticker_map = {\n",
    "    'benchmark': ['SPY'],\n",
    "    'equity': ['VTI','VTV','VOE','VBR','VEA','VWO'],\n",
    "    'fixed_income': ['VTIP', 'SHV', 'MUB', 'LQD', 'BNDX', 'EMB'],\n",
    "    'spy-sectors': ['XLE', 'XLU', 'XLK', 'XLB', 'XLP', 'XLY', 'XLI', 'XLV', 'XLF', 'XLRE'],\n",
    "    'ark-etfs': ['ARKG', 'ARKK', 'ARKQ', 'ARKW']\n",
    "}\n",
    "\n",
    "\n",
    "config = {\n",
    "    'spy-sectors' : {\n",
    "        'hold_cols': ['Symbol','Company Name', 'Index Weight'],\n",
    "        'hold_format': r'holdings-spy-',\n",
    "        'idx_col': 'Symbol',\n",
    "        'fname': 'spy-sectors',\n",
    "        'skiprows': 1\n",
    "    },\n",
    "    'ark-etfs' : {\n",
    "        'hold_cols': ['ticker','company', 'weight(%)'],\n",
    "        'hold_format': r'holdings-ark-',\n",
    "        'idx_col': 'ticker',\n",
    "        'fname': 'ark-etfs',\n",
    "        'skiprows': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "hold_cols = config[universe]['hold_cols']\n",
    "hold_format = config[universe]['hold_format']\n",
    "idx_col = config[universe]['idx_col']\n",
    "fname = config[universe]['fname']\n",
    "skiprows = config[universe]['skiprows']\n",
    "\n",
    "companies = pd.DataFrame([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def clean_idx(df, s):\n",
    "    dfidx = df.index.dropna()\n",
    "    df = df.loc[dfidx].copy()\n",
    "    rows = df[df.index.str.contains(s) == True]\n",
    "    if len(rows) > 0:\n",
    "        idx = df[df.index.str.contains(s) == True].index\n",
    "        df = df.drop(idx, axis=0)\n",
    "    return df\n",
    "\n",
    "# Load component from ETF holding CSVs\n",
    "col_names = ['Symbol','Company', 'Weight']\n",
    "def load_components(cos, pattern, cols, idxcol, sectors, srows=1):\n",
    "    flist = os.listdir(component_path)\n",
    "    files = [f for f in flist if f.startswith(pattern)]\n",
    "    for s in sectors:\n",
    "        fname = component_path + pattern + s.lower() + '.csv'\n",
    "        print(fname)\n",
    "        df = pd.read_csv(fname, skiprows=srows, index_col=idxcol, usecols=cols)\n",
    "        df.index.name = col_names[0]\n",
    "        df.columns = col_names[1:]\n",
    "        df = clean_idx(df, ' ')\n",
    "        df['ETF'] = s\n",
    "        sector_tickers_map[s] = df.index.tolist()\n",
    "        cos = cos.append(df)\n",
    "    return cos\n",
    "\n",
    "companies = load_components(\n",
    "    companies, hold_format, hold_cols, \n",
    "    idx_col, ticker_map[universe], srows=skiprows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if(active_etf != None):\n",
    "    companies = companies[companies['ETF']==active_etf] # filter by selected ETF\n",
    "\n",
    "# run optimization with best gamma, returns initial weights\n",
    "px_portion, returns, alloc, pdf = recommend_allocs(\n",
    "    consol_px, frame, lb, frequency, min_gross, max_gross, min_w, max_w, gamma_val)\n",
    "rec = last_allocation(alloc, 0.01)\n",
    "tickers = rec.index.tolist()\n",
    "recommend = rec.copy()\n",
    "cos_no_dup = companies.drop_duplicates(subset='Company')\n",
    "recommend['Sector'] = cos_no_dup.loc[tickers]['ETF']\n",
    "recommend['Company'] = cos_no_dup.loc[tickers][['Company']]\n",
    "recommend = recommend.astype({\"Allocation\": np.float})\n",
    "recommend[['Company', 'Sector', 'Allocation']]\n",
    "recommend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# plots all tickers to verify if there are any M&A targets\n",
    "for t in recommend.sort_index().index:\n",
    "    consol_px[t][-frame:].plot()\n",
    "    plt.title(companies.loc[t]['Company'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sect_group_stats(col):\n",
    "    re_group = recommend.groupby(by=col)\n",
    "    print(\"Total % Allocation {0:.2f}\".format(recommend.Allocation.sum() * 100));\n",
    "    sector_cols = ['Sector Weight', 'Avg Position']\n",
    "    sector_df = pd.DataFrame([], index=pd.unique(recommend[col]), columns=sector_cols)\n",
    "    sector_df[sector_df.columns[0]] = re_group.sum()\n",
    "    sector_df[sector_df.columns[1]] = re_group.mean()\n",
    "    return sector_df\n",
    "\n",
    "sect_group_stats('Sector')\n",
    "\n",
    "\n",
    "recommend.to_pickle(\"recommend.pkl\")\n",
    "px_portion.to_pickle(\"px_portion.pkl\")\n",
    "rec.to_pickle(\"rec.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
