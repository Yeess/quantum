{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OBJECTIVES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. pull information going back to 2000\n",
    "2. breakdown port allocations in key reusable methods\n",
    "3. implement date rules to perform optimization at given intervals (date resample)\n",
    "4. calculate cumulative portfolio returns as portfolio allocation changes\n",
    "5. run sensitivities fine-tunning opt parameters (MVO day window, pos sizing, leverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cvx\n",
    "import re, os\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "pattern = r'holdings-'\n",
    "path = \"./sector_components/\"\n",
    "date_fmt = '%m-%d-%Y'\n",
    "log = False\n",
    "\n",
    "ticker_map = {\n",
    "    'benchmark': ['SPY'],\n",
    "    'equity': ['VTI','VTV','VOE','VBR','VEA','VWO'],\n",
    "    'fixed_income': ['VTIP', 'SHV', 'MUB', 'LQD', 'BNDX', 'EMB'],\n",
    "    'spy_sectors': ['XLE', 'XLU', 'XLK', 'XLB', 'XLP', 'XLY', 'XLI', 'XLV', 'XLF', 'XLRE']\n",
    "}\n",
    "\n",
    "dwld_key = 'XLV'\n",
    "sectors = ticker_map['spy_sectors']\n",
    "sector_tickers_map = {}\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(ticker_map.keys())[3]\n",
    "print(\"retrieving prices for:\", key, ticker_map[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     8
    ]
   },
   "outputs": [],
   "source": [
    "compound = lambda x: (x + 1).cumprod()\n",
    "two_dec = lambda x: '%.4f' % x\n",
    "# need to fix this method\n",
    "def get_pricing(fname, ticker_list, start_date):\n",
    "    if log: print(\"Getting pricing for:\", ticker_list, start_date)\n",
    "    px = web.DataReader(ticker_list,data_source='yahoo',start=start_date)['Adj Close']\n",
    "    px.to_csv(fname)\n",
    "    return px\n",
    "def show_weights(weights, labels, ret, sigma):\n",
    "    df = pd.DataFrame(weights, columns=labels)\n",
    "    df['return'] = ret * 252\n",
    "    df['sigma'] = sigma * np.sqrt(252)\n",
    "    df['sharpe'] = df['return'] / df['sigma']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8,
     24
    ]
   },
   "outputs": [],
   "source": [
    "def get_mean_variance(rets):\n",
    "    w_len = rets.shape[1] # number of columns\n",
    "    eq_weights = np.asarray([1/w_len for _ in range(w_len)]) #default weights\n",
    "    mu = rets.mean()\n",
    "    std_dev = rets.std()\n",
    "    cov_matrix = rets.cov()\n",
    "    return w_len, eq_weights, mu.values, std_dev, cov_matrix.values    \n",
    "#this replaces the method above WIP\n",
    "def get_mvo_allocations(rets, min_sum=1, max_sum=1, min_w=0, max_w=0.2):\n",
    "\n",
    "    w_len = rets.shape[1] # number of columns\n",
    "    eq_weights = np.asarray([1/w_len for _ in range(w_len)]) #default weights    \n",
    "    mu, Sigma, w = rets.mean().T, rets.cov(), cvx.Variable(w_len)\n",
    "    \n",
    "    gamma = cvx.Parameter(sign='positive')\n",
    "    ret = mu.T * w \n",
    "    risk = cvx.quad_form(w, Sigma)\n",
    "    prob = cvx.Problem(cvx.Maximize(ret - gamma*risk), \n",
    "        [cvx.sum_entries(w) >= min_sum, \n",
    "         cvx.sum_entries(w) <= max_sum, \n",
    "         w > min_w,\n",
    "         w < max_w])\n",
    "    gamma.value = 0.5; prob.solve()\n",
    "    if prob.status == 'optimal': return [i[0] for i in w.value.tolist()]\n",
    "def get_mvo_allocations(n, mu_ret, cov_mtrx, min_sum=1, max_sum=1, min_w=0, max_w=0.2):\n",
    "    mu = mu_ret.T\n",
    "    Sigma = cov_mtrx\n",
    "    w = cvx.Variable(n)\n",
    "    gamma = cvx.Parameter(sign='positive')\n",
    "    ret = mu.T * w \n",
    "    risk = cvx.quad_form(w, Sigma)\n",
    "    prob = cvx.Problem(cvx.Maximize(ret - gamma*risk), \n",
    "        [cvx.sum_entries(w) >= min_sum, \n",
    "         cvx.sum_entries(w) <= max_sum, \n",
    "         w > min_w,\n",
    "         w < max_w])\n",
    "    gamma.value = 0.5; prob.solve()\n",
    "    if prob.status == 'optimal': \n",
    "        return [i[0] for i in w.value.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     7,
     10,
     15
    ]
   },
   "outputs": [],
   "source": [
    "p_template = \"Ann. return: {0:.2f}%, std dev: {1:.2f}%, sharpe: {2:.2f}\"\n",
    "def calc_port_performance(arr, weights):\n",
    "    return np.cumprod(np.sum(arr * weights, axis=1) + 1)\n",
    "def date_rules(date_range, tgt_date_str, freq):\n",
    "    #return a list of dates\n",
    "    tgt_dt = datetime.strptime(tgt_date_str, date_fmt)\n",
    "    return date_range[:date_range.index(tgt_dt)+1][::-freq]\n",
    "def date_intervals(df, freq):\n",
    "    #using pandas\n",
    "    return df.resample(freq, closed='left', label='left').mean()\n",
    "def portfolio_metrics(pdf):\n",
    "    ret = (pdf.pct_change().mean() * 252).values[0]\n",
    "    std = (pdf.pct_change().std() * sqrt(252)).values[0]\n",
    "    print(p_template.format(ret * 100, std * 100, ret / std))\n",
    "    return ret, std, ret / std\n",
    "def recomend_allocs(w, irange, top):\n",
    "    w = (w.loc[irange].sum(axis=0).sort_values(ascending=False) / max_w_const).astype(np.int)\n",
    "    return w[:top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_weights(px, freq, lb=20, min_sum=1, max_sum=1, min_w=0, max_w=0.1):\n",
    "    px.dropna(axis=1, inplace=True)\n",
    "    returns = px.sort_index().pct_change(); returns.iloc[0] = 0\n",
    "    intervals = pd.to_datetime(date_intervals(returns, freq).index.tolist())\n",
    "    valid_dates = [d for d in intervals if d in returns.index]    \n",
    "    #cols = returns.columns    \n",
    "    hist_alloc = pd.DataFrame(np.zeros((returns.shape)), index=returns.index, columns=returns.columns)\n",
    "    if log: \n",
    "        print(\"Empty allocations:\", hist_alloc.shape)\n",
    "        print('{0:d} stocks, {1:d} days, {2:d} lookback'.format(len(returns.columns), len(px), lb))\n",
    "\n",
    "    for i in valid_dates:\n",
    "        lb_returns = returns.loc[:i.date()].tail(lb).dropna()\n",
    "        weights = np.array([0 for _ in range(len(returns.columns))])\n",
    "        if (len(lb_returns) > 2):\n",
    "            n, weights, mu_ret, std_dev, cov_mtrx = get_mean_variance(lb_returns)\n",
    "            weights = get_mvo_allocations(\n",
    "                n, mu_ret, cov_mtrx, min_sum=min_sum, max_sum=max_sum, min_w=min_w, max_w=max_w)\n",
    "        hist_alloc.loc[i.date()] = weights\n",
    "\n",
    "    hist_alloc = hist_alloc.loc[returns.index].replace(0, np.nan).fillna(method='ffill')\n",
    "    hist_alloc.replace(np.nan, 0, inplace=True)\n",
    "    \n",
    "    if log: print(\"returns: rows / cols\", returns.shape, \"allocation: rows / cols\", hist_alloc.shape)\n",
    "    return returns, hist_alloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Test Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "numdays, cols = 100, 10\n",
    "end_date_str, tgt_date_str = '12-31-2017', '12-27-2017'\n",
    "freq = 7; lookback = 20\n",
    "\n",
    "arr = (np.random.rand(numdays, cols) - 0.5) / 10\n",
    "weights = np.random.rand(1, cols)\n",
    "weights = weights / np.sum(weights, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test the portfolio performance calculation\n",
    "port_perf = calc_port_performance(arr, weights)\n",
    "#pd.DataFrame(port_perf).plot()\n",
    "port_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test the date rules / intervals\n",
    "end_date = datetime.strptime(end_date_str, date_fmt)\n",
    "d_rng = sorted([end_date - timedelta(x) for x in range(0, numdays)]) # using list comprenhensions\n",
    "sorted(date_rules(d_rng, tgt_date_str, freq))\n",
    "\n",
    "d_rng = pd.date_range(end=end_date_str, freq='D', periods=numdays) # using pandas date range\n",
    "d_rng = list(pd.to_datetime(d_rng))\n",
    "intervals = list(sorted(date_rules(d_rng, tgt_date_str, freq)))\n",
    "print(\"check:\", len(intervals), \"equals\", numdays // freq, \"result:\",len(intervals) == numdays // freq) # check if intervals works\n",
    "intervals[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d_rng = pd.date_range(end=end_date_str, freq='D', periods=numdays) # using pandas date range\n",
    "d_rng = list(pd.to_datetime(d_rng))\n",
    "\n",
    "df = pd.DataFrame(arr, index=d_rng, columns=[i for i in range(cols)])\n",
    "(df+1).cumprod().mean(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test both the portfolio performance using date intervals without optimization / equal weights\n",
    "date_range = list(df.index)\n",
    "intervals = list(sorted(date_rules(date_range, tgt_date_str, freq)))\n",
    "hist_alloc = pd.DataFrame(np.zeros((len(df),cols)), index=df.index)\n",
    "\n",
    "for i in intervals:\n",
    "    #lb_returns = df.loc[:i.date()].tail(lookback)\n",
    "    weights = np.array([1/cols for _ in range(cols)])\n",
    "    #print(['{0:.2f}'.format(x) for x in weights])\n",
    "    hist_alloc.loc[i.date()] = weights\n",
    "\n",
    "hist_alloc.loc[intervals[0]:] = hist_alloc.loc[intervals[0]:].replace(0, np.nan).fillna(method='ffill')\n",
    "\n",
    "port_perf = calc_port_performance(df.values, hist_alloc.values)\n",
    "pd.DataFrame(port_perf).plot()\n",
    "port_perf[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#test both the portfolio performance using date intervals with optimization\n",
    "date_range = list(df.index)\n",
    "intervals = list(sorted(date_rules(date_range, tgt_date_str, freq)))\n",
    "hist_alloc = pd.DataFrame(np.zeros((len(df),cols)), index=df.index)\n",
    "\n",
    "for i in intervals:\n",
    "    lb_returns = df.loc[:i.date()].tail(lookback)\n",
    "    n, weights, mean_returns, std_dev, cov_matrix = get_mean_variance(lb_returns)\n",
    "    weights = get_mvo_allocations(n, mean_returns, cov_matrix, min_w=0.0, max_w=0.3)\n",
    "    #print(['{0:.2f}'.format(x) for x in weights])\n",
    "    hist_alloc.loc[i.date()] = weights\n",
    "\n",
    "hist_alloc.loc[intervals[0]:] = hist_alloc.loc[intervals[0]:].replace(0, np.nan).fillna(method='ffill')\n",
    "hist_alloc\n",
    "\n",
    "port_perf = calc_port_performance(df.values, hist_alloc.values)\n",
    "pdf = pd.DataFrame(port_perf)\n",
    "pdf.plot()\n",
    "port_perf[-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load from hard-drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "# load sector components\n",
    "flist = os.listdir(path)\n",
    "files = [f for f in flist if f.startswith(pattern)]\n",
    "colstoload = ['Symbol','Company Name', 'Index Weight']\n",
    "numdays, cols = 252, 10; freq = \"W-WED\"; lookback = 20; hist_window = 252*5\n",
    "end_date_str = tgt_date_str = '1-8-2018'\n",
    "start_date = datetime.strptime('1-8-2018', date_fmt)\n",
    "start_date = start_date - timedelta(hist_window)\n",
    "companies = pd.DataFrame([])\n",
    "\n",
    "for s in sectors:\n",
    "    fname = path + pattern + s.lower() + '.csv'\n",
    "    df = pd.read_csv(fname, skiprows=1, index_col='Symbol', usecols=colstoload)\n",
    "    df['ETF'] = s\n",
    "    sector_tickers_map[s] = df.index.tolist()\n",
    "    companies = companies.append(df)\n",
    "\n",
    "if log: print(\"Company Sample:\", companies.shape); print(companies.groupby('ETF')['Index Weight'].count())\n",
    "\n",
    "# LOAD FROM HARD DRIVE\n",
    "px = pd.read_csv(dwld_key + '-hold-pricing.csv', index_col='Date', parse_dates=True)\n",
    "spyder_etf = pd.read_csv(dwld_key + '.csv', index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data from the Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HITS THE SERVER: downloads data from yahoo for all tickers for a given sector + ETF for same date range\n",
    "tickers = sector_tickers_map[dwld_key] # for individual components\n",
    "#tickers = ticker_map[\"spy_sectors\"] # for individual ETFs\n",
    "px = get_pricing(dwld_key + '-hold-pricing.csv', tickers, start_date.strftime(date_fmt))\n",
    "etf = get_pricing(dwld_key + '.csv', dwld_key, start_date.strftime(date_fmt))\n",
    "spyder_etf = pd.DataFrame(etf)\n",
    "spyder_etf.index.name = \"Date\"\n",
    "spyder_etf.columns=[dwld_key]\n",
    "spyder_etf.to_csv(dwld_key + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = (-252*3); max_w_const = 0.1\n",
    "px.dropna(axis=0, inplace=True)\n",
    "px.dropna(axis=1, inplace=True)\n",
    "px_portion = px[frame:].copy()\n",
    "s_etf = (spyder_etf[frame:].pct_change() + 1).cumprod()\n",
    "returns, alloc = get_weights(px_portion, \"W-WED\", max_w=max_w_const)\n",
    "port_perf = calc_port_performance(returns.values, alloc.values)\n",
    "pdf = pd.DataFrame(port_perf, index=returns.index, columns=[dwld_key + \"-cvxopt\"])\n",
    "portfolio_metrics(pdf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pdf.plot(); s_etf.plot(ax=ax, legend='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"Portfolio metrics starting every {} trading days and holding for {} days\"\n",
    "holding = 252; stop = int(len(alloc) - holding); jumps = 14\n",
    "offsets = [x for x in range(0, stop, jumps)]\n",
    "print(msg.format(jumps, holding))\n",
    "results = []\n",
    "for o in offsets:\n",
    "    start = np.min([o, len(alloc)-1])\n",
    "    end = np.min([o+holding, len(alloc)])\n",
    "    p = px[start:end].copy()\n",
    "    s_etf = (spyder_etf[start:end].pct_change() + 1).cumprod()\n",
    "    r, w = get_weights(p, \"W-WED\", max_w=0.10)\n",
    "    port_perf = calc_port_performance(r.values, w.values)\n",
    "    pdf = pd.DataFrame(port_perf, index=r.index) # index by date\n",
    "    results.append(pdf[-1:].values[0][0])\n",
    "    #portfolio_metrics(pdf)\n",
    "pd.DataFrame(results, columns=[\"Return\"]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show portfolio metrics for a given time window\n",
    "length = 252\n",
    "w = alloc[-length:].astype(np.float)\n",
    "r = returns[-length:].astype(np.float)\n",
    "port_perf = calc_port_performance(r.values, w.values)\n",
    "pdf = pd.DataFrame(port_perf, index=r.index, columns=[dwld_key + \"-cvxopt\"])\n",
    "portfolio_metrics(pdf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show top holdings and last recomended holding set\n",
    "w = alloc[-length:].astype(np.float16)\n",
    "intervals = pd.to_datetime(date_intervals(r, freq).index.tolist())\n",
    "\n",
    "top = 10\n",
    "irange = intervals\n",
    "print(\"Top {} holdings during the last {} intervals\".format(top, len(irange)))\n",
    "print(recomend_allocs(w, irange, top))\n",
    "\n",
    "irange = intervals[-5:]\n",
    "print(\"Top {} holdings during the last {} intervals\".format(top, len(irange)))\n",
    "print(recomend_allocs(w, irange, top))\n",
    "\n",
    "irange = intervals[-1:]\n",
    "print(\"Top {} holdings during the last {} intervals\".format(top, len(irange)))\n",
    "print(recomend_allocs(w, irange, top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show index return plots by year\n",
    "first_year = int(alloc.index[0].year)\n",
    "last_year = int(alloc.index[-1].year)\n",
    "years = [y for y in range(first_year, last_year, 1)] \n",
    "\n",
    "def perf_by_years(r, a, years):\n",
    "    ax = plt.axes()\n",
    "    for y in years:\n",
    "        year = str(y)\n",
    "        w = alloc.loc[year].astype(np.float16)\n",
    "        r = returns.loc[year].astype(np.float16)\n",
    "        p_perf = calc_port_performance(r.values, w.values)\n",
    "        result = pd.DataFrame(p_perf, index=w.index, columns=[year])\n",
    "        result.plot(title='Optimal Components of ' + dwld_key, ax=ax, legend='right')\n",
    "        #print(year, result[-1:].values[0][0])\n",
    "\n",
    "perf_by_years(returns, alloc, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK compounding math\n",
    "#what were the top 10 allocations tickers?\n",
    "top_stocks = alloc.sum(axis=0).sort_values(ascending=False)[:10].index.tolist()\n",
    "# what was their allocation?\n",
    "alloc = alloc[top_stocks]\n",
    "# how much did we allocate to them?\n",
    "cum_alloc = alloc.sum(axis=1)\n",
    "# multiply the daily returns of top allocations times our allocation\n",
    "port_return = (returns[top_stocks] * alloc).sum(axis=1)\n",
    "# we add 1 to get the compounding index\n",
    "port_index = (port_return + 1).cumprod()\n",
    "#cumulative return for the portfolio\n",
    "print(port_index[-1:], len(port_index), \"days\")\n",
    "\n",
    "port_perf = calc_port_performance(returns[top_stocks].values, alloc.values)\n",
    "print(port_perf[-1:], len(port_perf), \"days\")\n",
    "print(\"annual return\", pd.Series(port_perf).pct_change().mean() * 252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show behaviour during sepcific time window\n",
    "window = pdf.loc['2015-1-1':'2015-3-31']\n",
    "portfolio_metrics(window)\n",
    "window.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0.04\n",
      "5 0.08\n",
      "5 0.12\n",
      "5 0.16\n",
      "5 0.2\n",
      "10 0.04\n",
      "10 0.08\n",
      "10 0.12\n",
      "10 0.16\n",
      "10 0.2\n"
     ]
    }
   ],
   "source": [
    "lbs = [x for x in range(5, 15, 5)]\n",
    "mws = (np.array([x for x in range(4, 24, 4)]) / 100).tolist()\n",
    "for i, l in enumerate(lbs):\n",
    "    for j, w in enumerate(mws):\n",
    "        print(l, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def create_matrix(px, start, end, step):\n",
    "    lbs = [x for x in range(start, end, step)]\n",
    "    mws = (np.array([x for x in range(start, end, step)]) / 100).tolist()\n",
    "    df = pd.DataFrame([], index=mws, columns=lbs)\n",
    "    \n",
    "    for i, l in enumerate(lbs):\n",
    "        for j, w in enumerate(mws):\n",
    "            r, w = get_weights(px_portion, freq, lb=l, max_w=w)\n",
    "            port_perf = calc_port_performance(r.values, w.values)\n",
    "            pdf = pd.DataFrame(port_perf, index=r.index, columns=[dwld_key + \"-cvxopt\"])\n",
    "            days = len(pdf)\n",
    "            ret, std, sharpe = portfolio_metrics(pdf);\n",
    "            df.iloc[i, j] = (\n",
    "                ret.astype(np.float16), \n",
    "                std.astype(np.float16), \n",
    "                sharpe.astype(np.float16))\n",
    "    return df\n",
    "\n",
    "def heatmap(df, cmap = plt.cm.gray_r): \n",
    "    fig = plt.figure() \n",
    "    ax = fig.add_subplot(111) \n",
    "    axim = ax.imshow(df.values, cmap=cmap, interpolation='nearest')\n",
    "    ax.set_xlabel(df.columns.name) \n",
    "    ax.set_xticks(np.arange(len(df.columns)))\n",
    "    ax.set_xticklabels(list(df.columns))\n",
    "    ax.set_ylabel(df.index.name)\n",
    "    ax.set_yticks(np.arange(len(df.index)))\n",
    "    ax.set_yticklabels( list(df.index))\n",
    "    plt.colorbar(axim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ann. return: 41.35%, std dev: 16.41%, sharpe: 2.52\n",
      "Ann. return: 55.33%, std dev: 18.86%, sharpe: 2.93\n",
      "Ann. return: 66.43%, std dev: 20.65%, sharpe: 3.22\n",
      "Ann. return: 72.59%, std dev: 22.19%, sharpe: 3.27\n",
      "Ann. return: 33.41%, std dev: 16.11%, sharpe: 2.07\n",
      "Ann. return: 45.09%, std dev: 18.11%, sharpe: 2.49\n",
      "Ann. return: 47.83%, std dev: 19.63%, sharpe: 2.44\n",
      "Ann. return: 52.07%, std dev: 21.36%, sharpe: 2.44\n",
      "Ann. return: 30.57%, std dev: 15.71%, sharpe: 1.95\n",
      "Ann. return: 37.19%, std dev: 17.51%, sharpe: 2.12\n",
      "Ann. return: 41.23%, std dev: 19.00%, sharpe: 2.17\n",
      "Ann. return: 45.14%, std dev: 20.74%, sharpe: 2.18\n",
      "Ann. return: 27.87%, std dev: 15.68%, sharpe: 1.78\n",
      "Ann. return: 34.82%, std dev: 17.42%, sharpe: 2.00\n",
      "Ann. return: 38.29%, std dev: 19.07%, sharpe: 2.01\n",
      "Ann. return: 40.10%, std dev: 20.51%, sharpe: 1.95\n"
     ]
    }
   ],
   "source": [
    "sm = create_matrix(px, 4, 24, 4)\n",
    "#heatmap(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>12</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.04</th>\n",
       "      <td>2.519531</td>\n",
       "      <td>2.933594</td>\n",
       "      <td>3.216797</td>\n",
       "      <td>3.271484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>2.074219</td>\n",
       "      <td>2.490234</td>\n",
       "      <td>2.435547</td>\n",
       "      <td>2.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>1.946289</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>2.169922</td>\n",
       "      <td>2.175781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.16</th>\n",
       "      <td>1.777344</td>\n",
       "      <td>1.998047</td>\n",
       "      <td>2.007812</td>\n",
       "      <td>1.955078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            4         8         12        16\n",
       "0.04  2.519531  2.933594  3.216797  3.271484\n",
       "0.08  2.074219  2.490234  2.435547  2.437500\n",
       "0.12  1.946289  2.125000  2.169922  2.175781\n",
       "0.16  1.777344  1.998047  2.007812  1.955078"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract = lambda x: x[2]\n",
    "sm.applymap(extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Old Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for s in sector_tickers_map.keys():\n",
    "    print(len(sector_tickers_map[s]))\n",
    "    \n",
    "#test both the portfolio performance using date intervals with optimization\n",
    "df = pd.DataFrame(arr, index=d_rng, columns=[i for i in range(cols)])\n",
    "date_range = list(df.index)\n",
    "intervals = list(sorted(date_rules(date_range, tgt_date_str, freq)))\n",
    "hist_allocations = pd.DataFrame(np.zeros((len(intervals),cols)), index=pd.to_datetime(intervals))\n",
    "\n",
    "for i in intervals:\n",
    "    lb_returns = df.loc[:i.date()].tail(lookback)\n",
    "    w_len, weights, mean_returns, std_dev, cov_matrix = get_mean_variance(lb_returns)\n",
    "    weights = get_mvo_allocations(mean_returns, cov_matrix)\n",
    "    hist_allocations.loc[i.date()] = weights\n",
    "\n",
    "port_perf = calc_port_performance(df.loc[intervals].values, hist_allocations.values)\n",
    "pd.DataFrame(port_perf).plot()\n",
    "port_perf[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "px = get_pricing(ticker_map[key], '01/01/2017')\n",
    "returns = px.sort_index().pct_change()\n",
    "compound(returns).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "w_len, weights, mean_returns, std_dev, cov_matrix = get_mean_variance(returns)\n",
    "\n",
    "ann_returns = np.dot((mean_returns * 252), weights)\n",
    "ann_stdev = np.sqrt(252/len(returns)) * std_dev\n",
    "print(weights.shape, cov_matrix.shape)\n",
    "port_variance = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(252)\n",
    "print(\"eq weight return(exp)\", ann_returns)\n",
    "print(\"port risk(exp):\", port_variance)\n",
    "print(\"sharpe ratio:\", ann_returns / port_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Long only portfolio optimization.\n",
    "weights = get_mvo_allocations(mean_returns, cov_matrix)\n",
    "np_weights = np.array([weights]).T\n",
    "exp_return = np.dot(np.array([mean_daily_returns.values]), np_weights) * 252\n",
    "portfolio_std_dev = np.sqrt(np.dot(np_weights.T, np.dot(cov_matrix, np_weights))) * np.sqrt(252)\n",
    "print(\"optimized return(exp):\", exp_return)\n",
    "print(\"optimized portfolio risk(exp):\", portfolio_std_dev)\n",
    "print(\"sharpe ratio:\", exp_return / portfolio_std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compute trade-off curve.\n",
    "SAMPLES = 100\n",
    "weights = []\n",
    "risk_data = np.zeros(SAMPLES)\n",
    "ret_data = np.zeros(SAMPLES)\n",
    "gamma_vals = np.logspace(-2, 3, num=SAMPLES)\n",
    "for i in range(SAMPLES):\n",
    "    gamma.value = gamma_vals[i]\n",
    "    prob.solve()\n",
    "    weights.append([i[0] for i in w.value.tolist()])\n",
    "    risk_data[i] = cvx.sqrt(risk).value\n",
    "    ret_data[i] = ret.value\n",
    "print('Optimization status:', prob.status)\n",
    "#w.value, risk_data, ret_data\n",
    "#ret_data / risk_data # sharpe ratio\n",
    "#risk_data[np.argmin(risk_data)], risk_data[np.argmax(ret_data)]\n",
    "#wgt_cum_ret = (ret_data + 1).cumprod()\n",
    "cols = returns.columns.tolist();\n",
    "allocs = show_weights(weights, returns.columns, ret_data, risk_data); allocs.tail()\n",
    "allocs[cols].plot()\n",
    "print(allocs[-1:].apply(two_dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot long only trade-off curve.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "markers_on = range(1, 100, 10)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(risk_data, ret_data, 'g-')\n",
    "for marker in markers_on:\n",
    "    plt.plot(risk_data[marker], ret_data[marker], 'bs')\n",
    "    #ax.annotate(r\"$\\gamma = %.2f$\" % gamma_vals[marker], xy=(risk_data[marker], ret_data[marker]))\n",
    "for i in range(n):\n",
    "    plt.plot(sqrt(Sigma[i,i]).value, mu[i], 'ro')\n",
    "    ax.annotate(returns.columns[i], xy=(sqrt(Sigma[i,i]).value, mu[i]))\n",
    "plt.xlabel('Standard deviation')\n",
    "plt.ylabel('Return')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gamma_vals.shape, risk_data.shape, ret_data.shape\n",
    "summary = pd.DataFrame([], columns=['gamma', 'risk', 'return'], index=range(SAMPLES))\n",
    "summary['gamma'] = np.array([gamma_vals]).T\n",
    "summary['risk'] = np.array([risk_data]).T\n",
    "summary['return'] = np.array([ret_data]).T\n",
    "summary[['risk','return']].plot(kind='line')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
